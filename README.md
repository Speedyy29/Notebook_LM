# ğŸ“š NotebookLM Clone

A full-stack web application that allows users to upload PDF files and chat with an AI assistant about the document's contents. Built with React, Node.js, Express, and OpenAI's GPT-4o-mini.

![NotebookLM Clone](https://img.shields.io/badge/React-18.2.0-blue) ![Node.js](https://img.shields.io/badge/Node.js-18+-green) ![License](https://img.shields.io/badge/license-MIT-blue)

## âœ¨ Features

- **ğŸ“„ PDF Upload & Viewing**: Upload large PDF files (up to 50MB) with drag-and-drop support
- **ğŸ¤– AI-Powered Chat**: Ask questions about your documents and get intelligent responses
- **ğŸ” Smart Citations**: Every AI response includes clickable page citations
- **ğŸ“– Interactive PDF Viewer**: Navigate through pages with zoom controls and smooth scrolling
- **âš¡ Efficient Token Usage**: Semantic search ensures only relevant content is sent to the AI
- **ğŸ¨ Modern UI**: Clean, responsive interface inspired by Google NotebookLM
- **ğŸ“± Responsive Design**: Works seamlessly on desktop and tablet devices

## ğŸ—ï¸ Architecture

### Frontend
- **React 18** with Vite for fast development
- **TailwindCSS** for styling
- **react-pdf** for PDF rendering
- **Framer Motion** for smooth animations
- **Lucide React** for beautiful icons

### Backend
- **Node.js** with Express
- **OpenAI API** for embeddings and chat completions
- **pdf-parse** for PDF text extraction
- **In-memory vector store** for semantic search
- **Multer** for file upload handling

## ğŸ“‹ Prerequisites

Before you begin, ensure you have the following installed:

- **Node.js** (v18 or higher)
- **npm** or **yarn**
- **OpenAI API Key** ([Get one here](https://platform.openai.com/api-keys))

## ğŸš€ Installation & Setup

### 1. Clone or Extract the Project

```bash
cd notebooklm-clone
```

### 2. Backend Setup

```bash
# Navigate to backend directory
cd backend

# Install dependencies
npm install

# Create .env file
cp .env.example .env
```

Edit the `.env` file and add your OpenAI API key:

```env
OPENAI_API_KEY=your_openai_api_key_here
PORT=5000
NODE_ENV=development
FRONTEND_URL=http://localhost:3000
```

### 3. Frontend Setup

```bash
# Navigate to frontend directory (from project root)
cd frontend

# Install dependencies
npm install

# Create .env file
cp .env.example .env
```

The frontend `.env` should contain:

```env
VITE_API_URL=http://localhost:5000
```

## ğŸ¯ Running the Application

### Start Backend Server

```bash
# From backend directory
npm run dev
```

The backend server will start on `http://localhost:5000`

### Start Frontend Development Server

```bash
# From frontend directory (in a new terminal)
npm run dev
```

The frontend will start on `http://localhost:3000` and automatically open in your browser.

## ğŸ“– Usage Guide

### 1. Upload a PDF

- Click the upload area or drag and drop a PDF file
- Wait for the upload and processing to complete
- The system will automatically vectorize each page

### 2. Chat with Your Document

- Once uploaded, you'll see the chat interface with the PDF viewer
- Type your question in the input field at the bottom
- Press Enter or click the send button

### 3. Navigate with Citations

- AI responses include clickable page citations like `[Page 2]`
- Click any citation to jump directly to that page in the PDF viewer
- Use the PDF viewer controls to zoom and navigate manually

### 4. Example Questions

- "What is the main topic of this document?"
- "Summarize page 5"
- "What are the key conclusions?"
- "Explain the methodology used"

## ğŸ”§ Configuration

### Environment Variables

#### Backend (.env)

| Variable | Description | Default |
|----------|-------------|---------|
| `OPENAI_API_KEY` | Your OpenAI API key | Required |
| `PORT` | Backend server port | 5000 |
| `NODE_ENV` | Environment mode | development |
| `FRONTEND_URL` | Frontend URL for CORS | http://localhost:3000 |

#### Frontend (.env)

| Variable | Description | Default |
|----------|-------------|---------|
| `VITE_API_URL` | Backend API URL | http://localhost:5000 |

### AI Models Used

- **Chat**: `gpt-4o-mini` - Fast and cost-effective for conversations
- **Embeddings**: `text-embedding-3-small` - Efficient semantic search

## ğŸ“ Project Structure

```
notebooklm-clone/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ controllers/
â”‚   â”‚   â”œâ”€â”€ chatController.js      # Chat logic
â”‚   â”‚   â””â”€â”€ pdfController.js       # PDF upload logic
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ chatRoutes.js          # Chat endpoints
â”‚   â”‚   â””â”€â”€ pdfRoutes.js           # PDF endpoints
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ openaiClient.js        # OpenAI integration
â”‚   â”‚   â”œâ”€â”€ pdfParser.js           # PDF parsing
â”‚   â”‚   â””â”€â”€ vectorStore.js         # Vector storage
â”‚   â”œâ”€â”€ .env.example
â”‚   â”œâ”€â”€ .gitignore
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ server.js                  # Entry point
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatInput.jsx      # Message input
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatMessage.jsx    # Message display
â”‚   â”‚   â”‚   â”œâ”€â”€ FileUpload.jsx     # Upload component
â”‚   â”‚   â”‚   â”œâ”€â”€ PDFViewer.jsx      # PDF renderer
â”‚   â”‚   â”‚   â””â”€â”€ ProgressBar.jsx    # Upload progress
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatScreen.jsx     # Main chat UI
â”‚   â”‚   â”‚   â””â”€â”€ UploadScreen.jsx   # Upload UI
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â”œâ”€â”€ api.js             # API client
â”‚   â”‚   â”‚   â””â”€â”€ helpers.js         # Utility functions
â”‚   â”‚   â”œâ”€â”€ App.jsx                # Root component
â”‚   â”‚   â”œâ”€â”€ index.css              # Global styles
â”‚   â”‚   â””â”€â”€ main.jsx               # Entry point
â”‚   â”œâ”€â”€ .env.example
â”‚   â”œâ”€â”€ .gitignore
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ postcss.config.js
â”‚   â”œâ”€â”€ tailwind.config.js
â”‚   â””â”€â”€ vite.config.js
â”‚
â””â”€â”€ README.md
```

## ğŸ”Œ API Endpoints

### PDF Endpoints

#### Upload PDF
```http
POST /api/pdf/upload
Content-Type: multipart/form-data

Body: { pdf: File }

Response: {
  success: true,
  data: {
    documentId: string,
    fileName: string,
    totalPages: number,
    metadata: object
  }
}
```

#### Get Document Metadata
```http
GET /api/pdf/:documentId

Response: {
  success: true,
  data: {
    fileName: string,
    totalPages: number,
    uploadedAt: string
  }
}
```

#### Delete Document
```http
DELETE /api/pdf/:documentId

Response: {
  success: true,
  message: string
}
```

### Chat Endpoints

#### Send Message
```http
POST /api/chat
Content-Type: application/json

Body: {
  documentId: string,
  query: string,
  conversationHistory: array
}

Response: {
  success: true,
  data: {
    response: string,
    citations: number[],
    relevantPages: array
  }
}
```

#### Get Suggestions
```http
GET /api/chat/suggestions/:documentId

Response: {
  success: true,
  data: {
    suggestions: string[],
    documentName: string
  }
}
```

## ğŸ¨ Design Decisions

### Token Optimization
- **Semantic Search**: Only the top 3 most relevant pages are sent to the AI
- **Context Limiting**: Each page's text is used efficiently
- **Smart Chunking**: PDF pages are vectorized individually for precise retrieval

### User Experience
- **Two-Panel Layout**: Chat on the left, PDF viewer on the right
- **Smooth Animations**: Framer Motion for polished interactions
- **Responsive Citations**: Click to jump directly to referenced pages
- **Loading States**: Clear feedback during upload and processing

### Code Quality
- **Modular Architecture**: Separation of concerns (routes, controllers, utilities)
- **Error Handling**: Comprehensive error messages and validation
- **JSDoc Comments**: Full documentation for all functions
- **Clean Code**: ESLint-ready, follows best practices

## ğŸš¢ Deployment

### Frontend (Netlify)

1. Build the frontend:
```bash
cd frontend
npm run build
```

2. Deploy the `dist` folder to Netlify
3. Set environment variable: `VITE_API_URL=<your-backend-url>`

### Backend (Render/Vercel)

1. Push your code to GitHub
2. Connect to Render or Vercel
3. Set environment variables:
   - `OPENAI_API_KEY`
   - `FRONTEND_URL`
   - `NODE_ENV=production`

## ğŸ› ï¸ Development

### Code Style
- Use **camelCase** for variables and functions
- Use **PascalCase** for React components
- Add JSDoc comments for all functions
- Follow the existing code structure

### Adding Features

1. **Backend**: Add routes â†’ controllers â†’ utilities
2. **Frontend**: Add components â†’ pages â†’ utils
3. Test thoroughly before committing

## ğŸ› Troubleshooting

### Common Issues

**PDF not loading**
- Ensure the file is a valid PDF
- Check file size (max 50MB)
- Verify backend is running

**OpenAI errors**
- Verify API key is correct
- Check API quota and billing
- Ensure internet connection

**CORS errors**
- Verify `FRONTEND_URL` in backend .env
- Check both servers are running

**Upload fails**
- Check backend logs for errors
- Verify uploads directory exists
- Ensure sufficient disk space

## ğŸ“ License

This project is licensed under the MIT License.

## ğŸ™ Acknowledgments

- Inspired by [Google NotebookLM](https://notebooklm.google.com/)
- Built with [OpenAI API](https://openai.com/)
- UI components styled with [TailwindCSS](https://tailwindcss.com/)

## ğŸ“§ Support

For issues or questions, please check the troubleshooting section or review the code comments for detailed explanations.

---

**Built with â¤ï¸ using React, Node.js, and OpenAI**
